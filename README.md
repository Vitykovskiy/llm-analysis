# LLM Analysis

## Общие сведения
LLM Analysis — веб-ориентированная система для автоматизации сбора и формализации требований к информационным системам. Проект помогает вести диалоговый сбор требований, уточнять цели и роли, фиксировать и накапливать знания, формализовать требования.

## Описание применения программы
Программа поддерживает аналитическую деятельность на предпроектном этапе и обеспечивает:
- диалоговый сбор неструктурированных требований на естественном языке;
- последовательное уточнение целей, границ автоматизации и ролей пользователей;
- фиксацию и накопление знаний;
- формализацию требований.

## Область применения
- индивидуальные предприниматели и малый бизнес;
- разработчики, выполняющие анализ требований самостоятельно;
- учебные и исследовательские сценарии для моделирования процессов формирования требований.

## Среда функционирования
- сервер: Node.js;
- клиент: современный браузер (Chrome, Firefox, Edge);
- хранилище структурированных данных: SQLite;
- хранилище текстовых фрагментов: Chroma (опционально);
- интеграция с LLM через внешний API, совместимый с LangChain.

## Технологии
- TypeScript;
- NestJS (сервер);
- Vue 3 + Vuetify (клиент);
- LangChain (LLM-интеграция);
- SQLite и Chroma (данные).

## Основные программные модули
Подсистема | Модуль | Назначение
--- | --- | ---
Сервер | Модуль диалогового анализа требований | Приём описаний, взаимодействие с LLM-агентом, сохранение результатов диалога.
Сервер | Модуль управления аналитическими задачами | Декомпозиция задач, статусы и связи.
Сервер | Модуль интеграции с LLM | Формирование запросов к модели, вызов инструментов.
Сервер | Модуль хранения данных | SQLite для структурированных данных, Chroma для текстовых фрагментов (опция).
Клиент | Интерфейс диалогового взаимодействия | Ввод требований и просмотр истории.
Клиент | Интерфейс просмотра задач | Доска задач и статусы.
Клиент | Интерфейс просмотра результатов | Просмотр сформированных артефактов (диаграммы, сценарии, требования).

## Руководство программиста (актуальное)
### Требования
- Node.js 18+ (рекомендуется LTS).
- npm (идёт с Node.js).
- Опционально: Chroma DB, если требуется векторное хранилище.

### Установка
1) Установите зависимости фронтенда и бэкенда:
```bash
npm install
cd server && npm install
cd ../client && npm install
```
2) Скопируйте `.env` при необходимости и задайте переменные окружения:
- `LLM_API_TOKEN` — ключ LLM-провайдера (обязателен для работы агента).
- `LLM_MODEL` — при необходимости переопределяет модель (по умолчанию gpt-4.1).
- `CHROMA_URL` и `CHROMA_COLLECTION` — для включения Chroma (опционально).
- `SERVER_URL`, `CLIENT_URL` — адреса сервисов.

### Запуск в разработке
В одном терминале:
```bash
cd server
npm run start:dev
```
В другом терминале:
```bash
cd client
npm run dev
```

### Сборка и прод-запуск
```bash
cd server && npm run build && npm run start:prod
cd client && npm run build && npm run preview
```

### Тесты и проверка
```bash
cd server && npm test        # unit
cd server && npm run lint    # линт
```

### Расширение системы
- Добавляйте новые инструменты агента в `server/src/langchain`.
- Модифицируйте структуру задач в `server/src/tasks`.
- При необходимости подключайте другое хранилище, реализовав сервис вместо SQLite/Chroma.

## Руководство оператора
### Подготовка к работе
- Проверьте параметры окружения.
- Убедитесь в доступе к LLM-API.
- Проверьте доступность хранилищ данных.

### Работа с системой
Оператор:
- вводит исходное описание задачи автоматизации;
- отвечает на уточняющие вопросы агента;
- просматривает сформированные задачи и результаты;
- использует формализованные требования для проектирования.

### Резервное копирование
Сохраняйте файл SQLite при остановленном сервере; при использовании Chroma обеспечьте бэкап её хранилища.
